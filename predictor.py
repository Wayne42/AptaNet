# -*- coding: utf-8 -*-
"""Predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wy6sj_pwFDr3ET8Yw5hY0sq7exGgWT66
"""

from collections import Counter
import pandas as pd
import numpy as np
from imblearn.under_sampling import NeighbourhoodCleaningRule
from sklearn.model_selection import train_test_split
import pandas
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD
from sklearn.model_selection import StratifiedKFold
from sklearn.decomposition import PCA
from sklearn.decomposition import IncrementalPCA
from keras import regularizers
from keras.wrappers.scikit_learn import KerasClassifier
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from keras.utils import to_categorical
from collections import Counter
import sklearn
from keras.layers import Dense
from keras.layers import Dropout
from Sklearn.Cross_Validation import cross_val_score
from sklearn.model_selection import cross_val_score
from imblearn.under_sampling import NeighbourhoodCleaningRule
from sklearn.model_selection import KFold
from imblearn.under_sampling import RandomUnderSampler
from imblearn.under_sampling import NearMiss
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.cross_validation import train_test_split
from sklearn.cross_validation import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification


# Load dataset
dataset = pandas.read_csv("suppliementary Table S1.csv")

x=dataset.iloc[: ,1:640]

#print(x)
y=dataset['Class']

clf = RandomForestClassifier(n_estimators=300, max_depth=9,
                             random_state=0)
clf.fit(x, y) 
clf.feature_importances_  
model = SelectFromModel(clf, prefit=True)
x = model.transform(x)
x.shape  


ncr = NeighbourhoodCleaningRule()
x_resampled, y_resampled = ncr.fit_resample(x, y)


#Optimization Algorithm
opt=keras.optimizers.RMSprop(lr=0.00014, rho=0.9, epsilon=None, decay=0.0)

#Multi Layer Perceptron Model
model = Sequential()
model.add(Dense(128, input_dim=639, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)
  
model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)
  
model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)
  
model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)
  
model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)
  
model.add(Dense(128, activation='relu'))
keras.layers.AlphaDropout(0.3, noise_shape=None, seed=None)
  
model.add(Dense(1, activation='sigmoid'))
  
model.compile(loss='binary_crossentropy',
                optimizer=opt,
                metrics=['accuracy'])
  

# Estimator

model.fit(x_resampled, y_resampled,
          epochs=200,
          batch_size=310)
score = model.evaluate(x_resampled, y_resampled, batch_size=5000)

# Predictor
f=np.expand_dims(f, axis=0)
preds = model.predict(f)
model.predict_classes(f, batch_size=1, verbose=1)

#Print the Results
print(preds)
print(pp)